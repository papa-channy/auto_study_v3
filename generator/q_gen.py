import json
import random

from config.derived_config import DERIVED_CONFIG
from tools.paths import QUESTIONS_PATH, PROMPT_PATH, SETTING_PATH
from generator.q_gen_utils import parse_llm_response
from LLM.llm_selector import generate_by_llm

def generate_all_questions():
    """
    âœ… derived_config ê¸°ë°˜ ë¬¸ì œ ìë™ ìƒì„±ê¸°
    - ë„êµ¬ë³„ ë‚œì´ë„ Ã— í˜¸ì¶œíšŸìˆ˜ ë§Œí¼ LLM í˜¸ì¶œ
    - prompt.json ì°¸ì¡°í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìƒì„±
    - questions.jsonì— ëˆ„ì  ì €ì¥
    """
    tool_summary = DERIVED_CONFIG["tool_summary"]
    selected_datasets = DERIVED_CONFIG["random_datasets"]

    # LLM ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    with open(SETTING_PATH, encoding="utf-8") as f:
        config = json.load(f)
    llm_name = config.get("LLM", "groq")

    # 1ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ë¡œë”©
    with open(PROMPT_PATH, encoding="utf-8") as f:
        prompts = json.load(f)

    all_questions = []

    for tool, info in tool_summary.items():
        prompt = prompts.get(tool)
        if not prompt:
            print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ ëˆ„ë½: {tool}")
            continue

        print(f"\nğŸš€ [{tool.upper()}] ë¬¸ì œ ìƒì„± ì¤‘...")

        for level in info["difficulties"]:
            for _ in range(info["calls"]):
                dataset = random.choice(selected_datasets)

                # ğŸ”¥ LLM í˜¸ì¶œ (tool, count ì¸ì ì œê±°ë¨)
                raw = generate_by_llm(prompt, llm_name=llm_name)
                parsed = parse_llm_response(raw, tool)

                # ë©”íƒ€ì •ë³´ ë¶€ì—¬
                for q in parsed:
                    q["tool"] = tool
                    q["dataset"] = dataset
                    q["difficulty"] = level

                all_questions.extend(parsed)

    # 2ï¸âƒ£ ê²°ê³¼ ì €ì¥
    with open(QUESTIONS_PATH, "w", encoding="utf-8") as f:
        json.dump(all_questions, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… ì „ì²´ ë¬¸ì œ {len(all_questions)}ê°œ ì €ì¥ ì™„ë£Œ (ğŸ“ questions.json)")
